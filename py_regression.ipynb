{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Regression in Python\n",
    "author: Kaleb Cervantes\n",
    "execute:\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "Last semester, we went over how to do regression in R. This is fairly straightfoward as we just use the functions `lm` and `glm` to make the models. In R, we simply needed the data, and the formula. However this is more complicated in Python.\n",
    "\n",
    "First I will want to import the following libraries:\n",
    "\n",
    "* `sklearn` for the linear and logistic regression functions\n",
    "\n",
    "* `numpy` for matrix stuff\n",
    "\n",
    "* `pandas` for viewing dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also be using the auction verification dataset from UCI repository. This is because it has both a numeric and binary response for linear and logistic regression respectively. The head of the data is given in the following three tables. The first two are predictors, and the third are responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process.b1.capacity</th>\n",
       "      <th>process.b2.capacity</th>\n",
       "      <th>process.b3.capacity</th>\n",
       "      <th>process.b4.capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   process.b1.capacity  process.b2.capacity  process.b3.capacity  \\\n",
       "0                    0                    0                    2   \n",
       "1                    0                    0                    2   \n",
       "2                    0                    0                    2   \n",
       "3                    0                    0                    2   \n",
       "\n",
       "   process.b4.capacity  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auction_data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "auction_data.iloc[0:4, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property.price</th>\n",
       "      <th>property.product</th>\n",
       "      <th>property.winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   property.price  property.product  property.winner\n",
       "0              59                 1                0\n",
       "1              59                 2                0\n",
       "2              59                 4                0\n",
       "3              59                 6                0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auction_data.iloc[0:4, 4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verification.result</th>\n",
       "      <th>verification.time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>163.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>200.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>154.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>108.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verification.result  verification.time\n",
       "0                False         163.316667\n",
       "1                False         200.860000\n",
       "2                False         154.888889\n",
       "3                False         108.640000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auction_data.iloc[0:4, 7:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing The Data\n",
    "It may help to understand the dimensions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2043, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auction_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data has a fairly large amount of observations, it may help to split the data into training and test sets. For this, it may help to identify the following responses:\n",
    "\n",
    "* `verification.result` for logistic regression\n",
    "\n",
    "* `verification.time` for linear regression\n",
    "\n",
    "## Handling Predictors\n",
    "It may help to do some exploration with the predictors first.\n",
    "Now it may be important to note that --- although all of the predictors are stored as integers --- there may be some categorical data. From reading the documentation, this seems to be the case for the following:\n",
    "\n",
    "* `property.product` --- product code for product currently being verified.\n",
    "\n",
    "* `property.winner` --- `0` if price was verified, otherwise bidder code for bidder currently being verified\n",
    "\n",
    "The above columns will be transformed using dummy variables, with their default value `0` being ignored. Conveniently, the responses are also the last two columns in the dataframe. This means that our predictors are the first seven columns. Since indeces in Python begin at 0, the following code chunk will extract the predictors and add dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(\n",
    "    auction_data.iloc[:, 0:7],\n",
    "    columns= [\"property.product\", \"property.winner\"],\n",
    "    drop_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may also help to note that the dimensions have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2043, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though most of these are dummy variables, they will add more coefficients to the regression model.\n",
    "\n",
    "## Splitting the Data\n",
    "Now that the predictors have been handled, we can split the data. This process may need to be repeated later on depending on the circumstances. This is actually one of the areas where Python is more straightfoward than --- base --- R.\n",
    "\n",
    "the function `sklearn.model_selection.train_test_split` splits the into training and test data. The first inputs for this function are the predictor matrix and response vector --- or vectors if splitting for multiple responses. By default this function does a 75-25 split for training and testing. We can specify the split by putting the desired ratio for either group in the parameters `test_size` or `train_size`. There is also the function `random_state` which can be used to specify the seed set for random sample used. Dr. Kerr used the R equivelent for reproducabiliity so I intend on doing the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lin = auction_data[\"verification.time\"]\n",
    "y_log = auction_data[\"verification.result\"]\n",
    "\n",
    "(\n",
    "    X_train, X_test,\n",
    "    y_lin_train, y_lin_test,\n",
    "    y_log_train, y_log_test\n",
    ") = train_test_split(\n",
    "    X, y_lin, y_log,\n",
    "    test_size = 0.4,\n",
    "    random_state = 2022\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been split, we can finally fit our model.\n",
    "\n",
    "# Linear Models\n",
    "Similar to `lm` in R, `sklearn.linear_model.LinearRegression` is an object for our linear model. The function `fit` will be used to actually fit the model.\n",
    "\n",
    "In order to see the $R^2$ coefficient, we use the function `score`. We will first check this for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6605544724598729"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1 = (\n",
    "    skl\n",
    "    .LinearRegression()\n",
    "    .fit(X_train, y_lin_train)\n",
    ")\n",
    "\n",
    "lm1.score(X_train, y_lin_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this it appears that `lm1` only accounts for about 66% of the variability in the model. Now we try to see what this value would be for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6182826928671714"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1.score(X_test, y_lin_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this it appears that only about 62% of the variability in the test data is accounted for by the model. This is not perfect, but given the $R^2$ for the training data this seems ok.\n",
    "\n",
    "If we want to see the coefficients of the model, we have to access the attributes `coef_` for the predictors and `intercept_` for the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8190.3895882599245"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5850.77182834,     84.72484738,  -1143.55239713,   2362.55568998,\n",
       "          -48.5921103 ,   9920.36748465, -10062.44991919,  -7612.87468259,\n",
       "        -5228.64958719,  -9800.90224685,  -5832.05652052,   1195.38994045,\n",
       "         1986.24482746,    691.72620791])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, the functions `lm`, `summary.lm`, and `plot.lm` do most of the above and much more. Unfortunately, Python doesn't allow for diagnostics to be done as easily. There are other packages beside sklearn that do them, but they are not as efficient as doing them in R. This is why --- although I prefer Python as a language over R --- R is much better for regression and diagnostics.\n",
    "\n",
    "# Logistic Regression\n",
    "When we split the data, we included both responses. Luckily this means that the splitting portion has been done for the logistic regression. Doing this is very similar to linear regression. It is important to note that by default, logistic regression in python applies an l2 penalty. This is similar to ridge regression. To remove the penalty, I set the parameter `penalty` to `\"none\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaleb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "glm1 = (\n",
    "    skl\n",
    "    .LogisticRegression(\"none\")\n",
    "    .fit(X_train, y_log_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the logistical model is fit, I will use `score` to check accuracy. Here `score` returns the number of correct predictions divided by the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9069387755102041"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm1.score(X_train, y_log_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902200488997555"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm1.score(X_test, y_log_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic model predicted with an accuracy of about 90% for both the test and training sets.\n",
    "\n",
    "Unfortunately, a lot of the model diagnostics still have to be manually done as there are not simple `plot.glm` or `summary.glm` in `scikitlearn`.\n",
    "\n",
    "# `statsmodels`\n",
    "`statsmodels` is a python library that allows users to use R-style formulas in Python. This would be useful for mixed model stuff, but in this document I will mostly use it to read model summaries.\n",
    "\n",
    "Since we are using this library, we will use the function `add_constant` to add the constant term to the training data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Tables\n",
    "Now we will view the model summary tables. There is a third table, but we did not go over what it shows in STAT 632. As such I will only show the first two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaleb\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>verification.time</td> <th>  R-squared:         </th> <td>   0.661</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.657</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   168.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 14 May 2022</td>  <th>  Prob (F-statistic):</th> <td>7.69e-272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:40:08</td>      <th>  Log-Likelihood:    </th> <td> -12425.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1225</td>       <th>  AIC:               </th> <td>2.488e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1210</td>       <th>  BIC:               </th> <td>2.496e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = add_constant(X_train)\n",
    "\n",
    "lm1_summary_tables = (\n",
    "    sm\n",
    "    .OLS(y_lin_train, X_train_sm)\n",
    "    .fit()\n",
    "    .summary()\n",
    "    .tables\n",
    ")\n",
    "\n",
    "lm1_summary_tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td> 8190.3896</td> <td> 2227.571</td> <td>    3.677</td> <td> 0.000</td> <td> 3820.059</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b1.capacity</th> <td> 5850.7718</td> <td>  261.338</td> <td>   22.388</td> <td> 0.000</td> <td> 5338.046</td> <td> 6363.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b2.capacity</th> <td>   84.7248</td> <td>  226.182</td> <td>    0.375</td> <td> 0.708</td> <td> -359.028</td> <td>  528.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b3.capacity</th> <td>-1143.5524</td> <td>  643.268</td> <td>   -1.778</td> <td> 0.076</td> <td>-2405.598</td> <td>  118.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b4.capacity</th> <td> 2362.5557</td> <td>  385.525</td> <td>    6.128</td> <td> 0.000</td> <td> 1606.185</td> <td> 3118.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.price</th>      <td>  -48.5921</td> <td>   27.998</td> <td>   -1.736</td> <td> 0.083</td> <td> -103.523</td> <td>    6.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_2</th>  <td> 9920.3675</td> <td>  547.889</td> <td>   18.107</td> <td> 0.000</td> <td> 8845.449</td> <td>  1.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_3</th>  <td>-1.006e+04</td> <td>  636.074</td> <td>  -15.820</td> <td> 0.000</td> <td>-1.13e+04</td> <td>-8814.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_4</th>  <td>-7612.8747</td> <td>  655.433</td> <td>  -11.615</td> <td> 0.000</td> <td>-8898.785</td> <td>-6326.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_5</th>  <td>-5228.6496</td> <td>  687.055</td> <td>   -7.610</td> <td> 0.000</td> <td>-6576.601</td> <td>-3880.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_6</th>  <td>-9800.9022</td> <td>  598.886</td> <td>  -16.365</td> <td> 0.000</td> <td> -1.1e+04</td> <td>-8625.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_1</th>   <td>-5832.0565</td> <td> 1137.179</td> <td>   -5.129</td> <td> 0.000</td> <td>-8063.118</td> <td>-3600.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_2</th>   <td> 1195.3899</td> <td>  780.814</td> <td>    1.531</td> <td> 0.126</td> <td> -336.509</td> <td> 2727.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_3</th>   <td> 1986.2448</td> <td>  765.638</td> <td>    2.594</td> <td> 0.010</td> <td>  484.120</td> <td> 3488.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_4</th>   <td>  691.7262</td> <td>  966.348</td> <td>    0.716</td> <td> 0.474</td> <td>-1204.177</td> <td> 2587.629</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1_summary_tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that both of the categorical variables have significant and insignificant levels. I will check Dr. Kerr's notes on how to handle these.\n",
    "\n",
    "The variable `process.b2.capacity` is not significant at any resonable level of $\\alpha$.\n",
    "\n",
    "We also notice that `property.price` and `process.b3.capacity` are not significant at the $\\alpha = 0.05$ level, but would be significant at the $\\alpha = 0.1$ level.\n",
    "\n",
    "## Logistic Regression Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.249993\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>  -11.7327</td> <td>    1.591</td> <td>   -7.375</td> <td> 0.000</td> <td>  -14.851</td> <td>   -8.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b1.capacity</th> <td>   -1.3342</td> <td>    0.208</td> <td>   -6.405</td> <td> 0.000</td> <td>   -1.742</td> <td>   -0.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b2.capacity</th> <td>   -0.3079</td> <td>    0.135</td> <td>   -2.287</td> <td> 0.022</td> <td>   -0.572</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b3.capacity</th> <td>   -0.0702</td> <td>    0.328</td> <td>   -0.214</td> <td> 0.831</td> <td>   -0.713</td> <td>    0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b4.capacity</th> <td>   -0.0463</td> <td>    0.238</td> <td>   -0.195</td> <td> 0.846</td> <td>   -0.512</td> <td>    0.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.price</th>      <td>    0.1464</td> <td>    0.021</td> <td>    7.026</td> <td> 0.000</td> <td>    0.106</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_2</th>  <td>   -0.2652</td> <td>    0.396</td> <td>   -0.669</td> <td> 0.503</td> <td>   -1.042</td> <td>    0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_3</th>  <td>    1.1049</td> <td>    0.373</td> <td>    2.960</td> <td> 0.003</td> <td>    0.373</td> <td>    1.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_4</th>  <td>    1.3371</td> <td>    0.410</td> <td>    3.257</td> <td> 0.001</td> <td>    0.533</td> <td>    2.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_5</th>  <td>   -0.8076</td> <td>    0.434</td> <td>   -1.863</td> <td> 0.063</td> <td>   -1.658</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_6</th>  <td>    1.3737</td> <td>    0.394</td> <td>    3.488</td> <td> 0.000</td> <td>    0.602</td> <td>    2.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_1</th>   <td>    5.1913</td> <td>    0.794</td> <td>    6.542</td> <td> 0.000</td> <td>    3.636</td> <td>    6.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_2</th>   <td>    2.1573</td> <td>    0.294</td> <td>    7.329</td> <td> 0.000</td> <td>    1.580</td> <td>    2.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_3</th>   <td>   -0.9584</td> <td>    0.498</td> <td>   -1.926</td> <td> 0.054</td> <td>   -1.934</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_4</th>   <td>    0.1983</td> <td>    0.430</td> <td>    0.461</td> <td> 0.644</td> <td>   -0.644</td> <td>    1.041</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    sm\n",
    "    .Logit(y_log_train, X_train_sm)\n",
    "    .fit()\n",
    "    .summary()\n",
    "    .tables[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced Models\n",
    "This is a bit more complicated in Python than it is in R. In R, we were able to remove predictors in the formula. In Python, we have to remove the corresponding columns in the dataframe or matrix. The following will remove the columns and refit the model.\n",
    "\n",
    "## Reduced Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaleb\\AppData\\Local\\Temp/ipykernel_12068/3627739673.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train_lin_reduced = X_train.drop(\n",
      "C:\\Users\\Kaleb\\AppData\\Local\\Temp/ipykernel_12068/3627739673.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test_lin_reduced = X_test.drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6585338975456794"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lin_reduced = X_train.drop(\n",
    "    [\"process.b2.capacity\", \"process.b3.capacity\", \"property.price\"],\n",
    "    1\n",
    ")\n",
    "X_test_lin_reduced = X_test.drop(\n",
    "    [\"process.b2.capacity\", \"process.b3.capacity\", \"property.price\"],\n",
    "    1\n",
    ")\n",
    "\n",
    "lm2 = (\n",
    "    skl\n",
    "    .LinearRegression()\n",
    "    .fit(X_train_lin_reduced, y_lin_train)\n",
    ")\n",
    "\n",
    "lm2.score(X_train_lin_reduced, y_lin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6124603279912988"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.score(X_test_lin_reduced, y_lin_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that there does not seem to be a significant difference in the $R^2$ from reducing the models. We can now look at the new table for the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaleb\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td> 3083.6728</td> <td>  491.000</td> <td>    6.280</td> <td> 0.000</td> <td> 2120.370</td> <td> 4046.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b1.capacity</th> <td> 5532.9222</td> <td>  228.843</td> <td>   24.178</td> <td> 0.000</td> <td> 5083.949</td> <td> 5981.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b4.capacity</th> <td> 2385.9731</td> <td>  385.147</td> <td>    6.195</td> <td> 0.000</td> <td> 1630.345</td> <td> 3141.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_2</th>  <td> 9808.2027</td> <td>  532.179</td> <td>   18.430</td> <td> 0.000</td> <td> 8764.109</td> <td> 1.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_3</th>  <td>-1.013e+04</td> <td>  629.158</td> <td>  -16.101</td> <td> 0.000</td> <td>-1.14e+04</td> <td>-8895.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_4</th>  <td>-7245.2568</td> <td>  630.906</td> <td>  -11.484</td> <td> 0.000</td> <td>-8483.045</td> <td>-6007.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_5</th>  <td>-5565.8221</td> <td>  655.438</td> <td>   -8.492</td> <td> 0.000</td> <td>-6851.741</td> <td>-4279.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_6</th>  <td>-9645.2083</td> <td>  578.390</td> <td>  -16.676</td> <td> 0.000</td> <td>-1.08e+04</td> <td>-8510.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_1</th>   <td>-6320.4783</td> <td> 1104.305</td> <td>   -5.723</td> <td> 0.000</td> <td>-8487.038</td> <td>-4153.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_2</th>   <td> 1010.4613</td> <td>  761.877</td> <td>    1.326</td> <td> 0.185</td> <td> -484.281</td> <td> 2505.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_3</th>   <td> 1719.5593</td> <td>  747.140</td> <td>    2.302</td> <td> 0.022</td> <td>  253.729</td> <td> 3185.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_4</th>   <td>  487.4516</td> <td>  955.656</td> <td>    0.510</td> <td> 0.610</td> <td>-1387.470</td> <td> 2362.373</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    sm\n",
    "    .OLS(y_lin_train, add_constant(X_train_lin_reduced))\n",
    "    .fit()\n",
    "    .summary()\n",
    "    .tables[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaleb\\AppData\\Local\\Temp/ipykernel_12068/488010461.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train_log_reduced = X_train.drop(\n",
      "C:\\Users\\Kaleb\\AppData\\Local\\Temp/ipykernel_12068/488010461.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test_log_reduced = X_test.drop(\n",
      "c:\\Users\\Kaleb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9044897959183673"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_log_reduced = X_train.drop(\n",
    "    [\"process.b3.capacity\", \"process.b4.capacity\"],\n",
    "    1\n",
    ")\n",
    "X_test_log_reduced = X_test.drop(\n",
    "    [\"process.b3.capacity\", \"process.b4.capacity\"],\n",
    "    1\n",
    ")\n",
    "\n",
    "glm2 = (\n",
    "    skl\n",
    "    .LogisticRegression(\"none\")\n",
    "    .fit(X_train_log_reduced, y_log_train)\n",
    ")\n",
    "\n",
    "glm2.score(X_train_log_reduced, y_log_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009779951100244"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm2.score(X_test_log_reduced, y_log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.250025\n",
      "         Iterations 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaleb\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>  -11.8459</td> <td>    1.535</td> <td>   -7.718</td> <td> 0.000</td> <td>  -14.854</td> <td>   -8.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b1.capacity</th> <td>   -1.3453</td> <td>    0.201</td> <td>   -6.709</td> <td> 0.000</td> <td>   -1.738</td> <td>   -0.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>process.b2.capacity</th> <td>   -0.3021</td> <td>    0.133</td> <td>   -2.273</td> <td> 0.023</td> <td>   -0.562</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.price</th>      <td>    0.1458</td> <td>    0.021</td> <td>    7.075</td> <td> 0.000</td> <td>    0.105</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_2</th>  <td>   -0.2775</td> <td>    0.389</td> <td>   -0.713</td> <td> 0.476</td> <td>   -1.040</td> <td>    0.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_3</th>  <td>    1.1044</td> <td>    0.373</td> <td>    2.960</td> <td> 0.003</td> <td>    0.373</td> <td>    1.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_4</th>  <td>    1.3415</td> <td>    0.410</td> <td>    3.269</td> <td> 0.001</td> <td>    0.537</td> <td>    2.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_5</th>  <td>   -0.8201</td> <td>    0.422</td> <td>   -1.942</td> <td> 0.052</td> <td>   -1.648</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.product_6</th>  <td>    1.3697</td> <td>    0.393</td> <td>    3.487</td> <td> 0.000</td> <td>    0.600</td> <td>    2.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_1</th>   <td>    5.1986</td> <td>    0.792</td> <td>    6.563</td> <td> 0.000</td> <td>    3.646</td> <td>    6.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_2</th>   <td>    2.1678</td> <td>    0.292</td> <td>    7.426</td> <td> 0.000</td> <td>    1.596</td> <td>    2.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_3</th>   <td>   -0.9585</td> <td>    0.497</td> <td>   -1.929</td> <td> 0.054</td> <td>   -1.933</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>property.winner_4</th>   <td>    0.1852</td> <td>    0.419</td> <td>    0.442</td> <td> 0.658</td> <td>   -0.635</td> <td>    1.006</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    sm\n",
    "    .Logit(y_log_train, add_constant(X_train_log_reduced))\n",
    "    .fit()\n",
    "    .summary()\n",
    "    .tables[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Regression can be done in Python and with the use of libraries like `statsmodels`, may offer the same tools that can be used in R. I think that with how common Python is, it is worth learning these methods. However they are not as simple as they are in R."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84a98fa6776ff90748a261c156da072e32c9b07ac5e4c0d6e14d135704831b66"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
